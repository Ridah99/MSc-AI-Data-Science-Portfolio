{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cc1c1694",
      "metadata": {
        "id": "cc1c1694"
      },
      "source": [
        "<h1 style = 'text-align: center'>Skin Cancer Detection Using Machine Learning</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2 style = 'text-align: center'>Import Necessary Libraries</h2>"
      ],
      "metadata": {
        "id": "5D5Wh1mu-_zS"
      },
      "id": "5D5Wh1mu-_zS"
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "spUsF8An6RvV"
      },
      "id": "spUsF8An6RvV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install kaggle"
      ],
      "metadata": {
        "id": "e7WvCxcG8ChM"
      },
      "execution_count": null,
      "outputs": [],
      "id": "e7WvCxcG8ChM"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "wpKwhzidP_Ui"
      },
      "execution_count": null,
      "outputs": [],
      "id": "wpKwhzidP_Ui"
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "hDNYoQXji0Ui"
      },
      "execution_count": null,
      "outputs": [],
      "id": "hDNYoQXji0Ui"
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/kaggle_API_credentials/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "un7VLJobizq6"
      },
      "execution_count": null,
      "outputs": [],
      "id": "un7VLJobizq6"
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "gTqp-HbWkbdK"
      },
      "execution_count": null,
      "outputs": [],
      "id": "gTqp-HbWkbdK"
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download -d hasnainjaved/melanoma-skin-cancer-dataset-of-10000-images"
      ],
      "metadata": {
        "id": "I_MtkjO-8d1m"
      },
      "id": "I_MtkjO-8d1m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip /content/melanoma-skin-cancer-dataset-of-10000-images.zip"
      ],
      "metadata": {
        "id": "kGteo_O1ir38"
      },
      "execution_count": null,
      "outputs": [],
      "id": "kGteo_O1ir38"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b112f88d",
      "metadata": {
        "id": "b112f88d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import backend\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from tensorflow.keras.applications import ResNet101V2, DenseNet121, InceptionV3\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Flatten, Dense, Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff106a2e",
      "metadata": {
        "id": "ff106a2e"
      },
      "source": [
        "<h2 style = 'text-align : center'>Data Preprocessing</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bcd4890",
      "metadata": {
        "id": "8bcd4890"
      },
      "source": [
        "<h3 style = 'text-align : center'>Define data directory</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07c63d9a",
      "metadata": {
        "id": "07c63d9a"
      },
      "outputs": [],
      "source": [
        "# Define the directory containing the training dataset\n",
        "\n",
        "data_dir = '/content/melanoma_cancer_dataset/train'\n",
        "\n",
        "# Define the directory containing the testing dataset\n",
        "\n",
        "test_dir = '/content/melanoma_cancer_dataset/test'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98f6db08",
      "metadata": {
        "id": "98f6db08"
      },
      "source": [
        "<h3 style = 'text-align : center'>Define batch size and image size</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdba55c5",
      "metadata": {
        "id": "cdba55c5"
      },
      "outputs": [],
      "source": [
        "# Define the batch size for training\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "# Define the dimensions for the images\n",
        "\n",
        "img_height = 224\n",
        "\n",
        "img_width = 224"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "355514f8",
      "metadata": {
        "id": "355514f8"
      },
      "source": [
        "<h3 style = 'text-align : center'>Load and the training and validation dataset</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e67222d",
      "metadata": {
        "id": "1e67222d"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess the training dataset\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "data_dir,\n",
        "validation_split = 0.2,\n",
        "subset = 'training',\n",
        "seed = 42,\n",
        "image_size = (img_height, img_width),\n",
        "batch_size = batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fa4e625",
      "metadata": {
        "id": "4fa4e625"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess the validation dataset\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "data_dir,\n",
        "validation_split = 0.2,\n",
        "subset = 'validation',\n",
        "seed = 42,\n",
        "image_size = (img_height, img_width),\n",
        "batch_size = batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess the testing dataset\n",
        "\n",
        "test_generator = ImageDataGenerator(\n",
        "\n",
        "    rescale = 1.0 /255.0    # Rescale the pixel values to range 0 - 1\n",
        ")\n",
        "\n",
        "test_ds = test_generator.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle = False\n",
        ")"
      ],
      "metadata": {
        "id": "mK1n1_HhL8XA"
      },
      "id": "mK1n1_HhL8XA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "3c0492c8",
      "metadata": {
        "id": "3c0492c8"
      },
      "source": [
        "<h3 style = 'text-align : center'>Data Visualisation</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac77896c",
      "metadata": {
        "id": "ac77896c"
      },
      "outputs": [],
      "source": [
        "# Get the class names from the training dataset\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "\n",
        "# Print the class names\n",
        "\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a count plot of the classes in the skin cancer dataset\n",
        "\n",
        "# Extract the labels from train_ds\n",
        "\n",
        "labels = []\n",
        "\n",
        "for idx, label in train_ds:\n",
        "    labels.extend(label.numpy().tolist())\n",
        "\n",
        "# Convert the labels to a NumPy array\n",
        "labels_array = np.array(labels)\n",
        "\n",
        "# Get the unique labels and their counts\n",
        "unique_labels, label_counts = np.unique(labels_array, return_counts = True)\n",
        "\n",
        "# Create a count plot using Matplotlib\n",
        "\n",
        "plt.figure(figsize = (8, 6))\n",
        "\n",
        "hist, bins, idx = plt.hist(labels_array, bins = np.arange(labels_array.min(), labels_array.max() +2) - 0.5,\n",
        "                         rwidth = 0.8, alpha = 0.75, color = 'pink', edgecolor = 'k')\n",
        "\n",
        "plt.xlabel(\"Dataset Classes\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xticks(unique_labels, class_names)\n",
        "plt.title(\"Count Plot of the Classes in the Train Set\", y = 1.05)\n",
        "\n",
        "\n",
        "# Add the total count for each class on top of each bar\n",
        "\n",
        "for i, count in enumerate(label_counts):\n",
        "\n",
        "    plt.text(unique_labels[i], count, str(count), ha = 'center', va = 'bottom')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8XJEC_hoKaRm"
      },
      "id": "8XJEC_hoKaRm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01fc8a48",
      "metadata": {
        "id": "01fc8a48"
      },
      "outputs": [],
      "source": [
        "# Print 16 images (4 x 4) with their labels from the training dataset\n",
        "\n",
        "# Create a figure for displaying images and set size to (10, 10)\n",
        "\n",
        "\n",
        "plt.figure(figsize = (10, 10))\n",
        "\n",
        "# Iterate over the first batch of images and labels in the training dataset\n",
        "for images, labels in train_ds.take(1):\n",
        "\n",
        "  # Loop through each image in the batch\n",
        "  for i in range(16):\n",
        "\n",
        "    # Create a subplot to display each image\n",
        "    ax = plt.subplot(4, 4, i + 1)\n",
        "\n",
        "    # Display the image\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "\n",
        "    # Set the title of the subplot to the corresponding class name\n",
        "    plt.title(class_names[labels[i]])\n",
        "\n",
        "    # Turn off axis labels\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "# Display the plot\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c06f9e4c",
      "metadata": {
        "id": "c06f9e4c"
      },
      "source": [
        "<h3 style = 'text-align : center'>Data Augmentation</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4773f4a6",
      "metadata": {
        "scrolled": false,
        "id": "4773f4a6"
      },
      "outputs": [],
      "source": [
        "# Data augmentation for the train dataset\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),  # Randomly flips the images horizontally.\n",
        "tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),       # Randomly rotates the images by up to 20%\n",
        "tf.keras.layers.experimental.preprocessing.RandomZoom(0.2),           # Randomly zooms the images by up to 20%\n",
        "tf.keras.layers.experimental.preprocessing.Rescaling(1.0 / 255)       # Rescale the pixel values to range 0 - 1\n",
        "])\n",
        "\n",
        "# Apply data augmentation to the train dataset\n",
        "\n",
        "train_ds = train_ds.map(lambda x, y: (data_augmentation(x, training = True), y))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3 style = 'text-align : center'>Normalization</h3>"
      ],
      "metadata": {
        "id": "i-isnVvUMiEX"
      },
      "id": "i-isnVvUMiEX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94806687",
      "metadata": {
        "id": "94806687"
      },
      "outputs": [],
      "source": [
        "# Normalization for val dataset\n",
        "\n",
        "val_normalization = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
        "\n",
        "# Apply normalization to the test dataset\n",
        "\n",
        "val_ds = val_ds.map(lambda x, y: (val_normalization(x), y))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3 style = 'text-align : center'>Class Weights</h3>"
      ],
      "metadata": {
        "id": "a27DFvnRM_Dm"
      },
      "id": "a27DFvnRM_Dm"
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the class weights\n",
        "\n",
        "# Getting the class labels in the dataset\n",
        "labels = [label.numpy() for _, label in train_ds]\n",
        "\n",
        "# Joining the labels together and converting to a list\n",
        "labels = np.concatenate(labels).tolist()\n",
        "\n",
        "# Using the compute_class_weight method from the sklearn module to calculate the class weights\n",
        "class_weights = compute_class_weight(\n",
        "                                        class_weight = \"balanced\",\n",
        "                                        classes = np.unique(labels),\n",
        "                                        y = labels\n",
        "                                    )\n",
        "# Create a dictionary with the class names as keys and corresponding weights\n",
        "class_weights = dict(zip(np.unique(labels), class_weights))\n",
        "\n",
        "class_weights"
      ],
      "metadata": {
        "id": "9566eT_9MaXn"
      },
      "id": "9566eT_9MaXn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c8b2ef0f",
      "metadata": {
        "id": "c8b2ef0f"
      },
      "source": [
        "## CNN Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7e50dc0",
      "metadata": {
        "id": "b7e50dc0"
      },
      "source": [
        "#### Define the CNN Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1132f4df",
      "metadata": {
        "id": "1132f4df"
      },
      "outputs": [],
      "source": [
        "# Define the CNN architecture using Sequential model\n",
        "\n",
        "model = Sequential([\n",
        "\n",
        "    # The input layer\n",
        "    layers.Conv2D(16, 3, padding = 'same', activation = 'relu', input_shape = (img_height,img_width, 3)),\n",
        "    layers.MaxPooling2D(),\n",
        "\n",
        "    # First hidden layer\n",
        "    layers.Conv2D(32, 3, padding = 'same', activation = 'relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "\n",
        "    # Second hidden layer\n",
        "    layers.Conv2D(32, 3, padding = 'same', activation = 'relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "\n",
        "    # Flattening layer\n",
        "    layers.Flatten(),\n",
        "\n",
        "    # Dense layer\n",
        "    layers.Dense(64, activation = 'relu'),\n",
        "    layers.Dropout(0.5), # Apply dropout regularisation\n",
        "\n",
        "    # Output layer\n",
        "    layers.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "\n",
        "# Print the model's architecture summary\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bb25e7c",
      "metadata": {
        "id": "1bb25e7c"
      },
      "source": [
        "#### Train the CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7778e068",
      "metadata": {
        "id": "7778e068"
      },
      "outputs": [],
      "source": [
        "# Compile the CNN model\n",
        "\n",
        "model.compile(optimizer = Adam(1e-5),\n",
        "loss = 'BinaryCrossentropy',\n",
        "metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d37e7f53",
      "metadata": {
        "id": "d37e7f53"
      },
      "outputs": [],
      "source": [
        "# Define the number of epochs for training\n",
        "\n",
        "epochs = 50\n",
        "\n",
        "# Train the model using the train dataset and validate using the val dataset\n",
        "\n",
        "history = model.fit(\n",
        "train_ds,\n",
        "validation_data = val_ds,\n",
        "class_weight = class_weights,\n",
        "epochs = epochs\n",
        ")\n",
        "\n",
        "# Extract accuracy, validation accuracy, loss, and validation loss from the training history\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Define the range of epochs for plotting\n",
        "\n",
        "epochs_range = range(epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e52d8def",
      "metadata": {
        "id": "e52d8def"
      },
      "source": [
        "#### CNN Model Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e501dc17",
      "metadata": {
        "id": "e501dc17"
      },
      "outputs": [],
      "source": [
        "# Plot for CNN Model Training and Validation Accuracy\n",
        "\n",
        "plt.figure(figsize = (8, 8))\n",
        "\n",
        "plt.plot(epochs_range, acc, label = 'Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label = 'Validation Accuracy')\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.title('CNN Model Training and Validation Accuracy')\n",
        "\n",
        "# Diplay the plot\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb35828e",
      "metadata": {
        "id": "eb35828e"
      },
      "outputs": [],
      "source": [
        "# Plot for CNN ModelTraining and Validation Loss\n",
        "\n",
        "plt.figure(figsize = (8, 8))\n",
        "\n",
        "plt.plot(epochs_range, loss, label = 'Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label = 'Validation Loss')\n",
        "plt.legend(loc = 'upper right')\n",
        "plt.title('CNN ModelTraining and Validation Loss')\n",
        "\n",
        "# Diplay the plot\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3af70c07",
      "metadata": {
        "id": "3af70c07"
      },
      "outputs": [],
      "source": [
        "# Define the class labels\n",
        "\n",
        "class_labels = ['Benign', 'Malignant']\n",
        "\n",
        "# Get the test labels\n",
        "\n",
        "y_true = test_ds.labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09dce6c1",
      "metadata": {
        "id": "09dce6c1"
      },
      "outputs": [],
      "source": [
        "# Get the prediction values using the trained model on the test dataset\n",
        "\n",
        "y_pred = model.predict(test_ds)\n",
        "\n",
        "# Get the class labels of the prediction values\n",
        "\n",
        "y_pred = np.round(y_pred).flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ccff3f8",
      "metadata": {
        "id": "5ccff3f8"
      },
      "outputs": [],
      "source": [
        "# print the CNN model's classification report\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names = class_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "887d43d5",
      "metadata": {
        "id": "887d43d5"
      },
      "outputs": [],
      "source": [
        "# Plot the CNN model's confusion matrix\n",
        "\n",
        "cnn_cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "sns.heatmap(cnn_cm, annot = True, fmt = \"d\", cmap = \"Blues\", cbar = True, xticklabels = class_labels,\n",
        "             yticklabels = class_labels)\n",
        "\n",
        "plt.title('CNN Model Confusion Matrix')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pretrained Models"
      ],
      "metadata": {
        "id": "POr0Mpo2AznX"
      },
      "id": "POr0Mpo2AznX"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a class Finetune_pretrained_models\n",
        "\n",
        "class Finetune_pretrained_models:\n",
        "\n",
        "    # Method to initializes the class Finetune_pretrained_models\n",
        "    def __init__(self, base_model):\n",
        "\n",
        "        # Clears the background session before training a new model\n",
        "        tf.keras.backend.clear_session()\n",
        "\n",
        "        # Loads a pre-trained model\n",
        "        self.base_model = base_model(weights = 'imagenet', include_top = False,\n",
        "                                           input_shape = (224, 224, 3))\n",
        "        self.model = None\n",
        "        self.history = None\n",
        "        self.finetuned_history = None\n",
        "        self.model_name = None\n",
        "\n",
        "    # Method to freeze the layers of the pre-trained model\n",
        "    def freeze_pretrained_model_layers(self):\n",
        "\n",
        "        self.base_model.trainable = False\n",
        "\n",
        "    # Method to unfreeze the layers and compile the pre-trained model\n",
        "    def unfreeze_pretrained_model_layers(self, learning_rate):\n",
        "\n",
        "        self.base_model.trainable = True\n",
        "\n",
        "        self.model.summary()\n",
        "\n",
        "        self.model.compile(\n",
        "\n",
        "            optimizer = Adam(learning_rate),\n",
        "            loss = 'BinaryCrossentropy',\n",
        "            metrics = ['accuracy']\n",
        "        )\n",
        "\n",
        "    # Method to define the architecture of the pretrained model\n",
        "    def define_pretrained_model_architecture(self, dropout_value, learning_rate):\n",
        "\n",
        "        inputs = tf.keras.Input(shape = (224, 224, 3))\n",
        "        x = inputs\n",
        "        x = self.base_model(x, training = False)\n",
        "        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "        x = tf.keras.layers.Dropout(dropout_value)(x)\n",
        "\n",
        "        outputs = tf.keras.layers.Dense(1, activation = 'sigmoid')(x)\n",
        "\n",
        "        self.model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "        self.model.compile(\n",
        "\n",
        "            optimizer = Adam(learning_rate),\n",
        "            loss = 'BinaryCrossentropy',\n",
        "            metrics = ['accuracy']\n",
        "        )\n",
        "\n",
        "        return self.model.summary()\n",
        "\n",
        "\n",
        "    # Method to fit the pretrained model on the dataset\n",
        "    def fit_model(self, epochs):\n",
        "        self.history = self.model.fit(\n",
        "\n",
        "            train_ds,\n",
        "            epochs = epochs,\n",
        "            class_weight = class_weights,\n",
        "            validation_data = val_ds\n",
        "        )\n",
        "\n",
        "    # Method to fit the finetuned pretrained model on the dataset\n",
        "    def fit_fine_tuned_model(self, epochs):\n",
        "        self.fine_tuned_history = self.model.fit(\n",
        "            train_ds,\n",
        "            epochs = epochs,\n",
        "            class_weight = class_weights,\n",
        "            validation_data = val_ds,\n",
        "        )\n",
        "\n",
        "    # Method to plot the training and validation accuracy and loss for the pretrained model\n",
        "    def plot_accuracy_and_loss(self, model_name, acc_y_lower_lim, loss_y_upper_limit):\n",
        "\n",
        "        initial_epochs = self.history.epoch[-1]\n",
        "\n",
        "        acc = self.history.history['accuracy'] + self.fine_tuned_history.history['accuracy']\n",
        "        val_acc = self.history.history['val_accuracy'] + self.fine_tuned_history.history['val_accuracy']\n",
        "        loss = self.history.history['loss'] + self.fine_tuned_history.history['loss']\n",
        "        val_loss = self.history.history['val_loss'] + self.fine_tuned_history.history['val_loss']\n",
        "\n",
        "        # Calculate the y-axis tick positions for increments of 0.2\n",
        "        acc_y_ticks = np.arange(acc_y_lower_lim, 1.02, 0.02)\n",
        "        loss_y_ticks = np.arange(0, loss_y_upper_limit + 0.02, 0.02)\n",
        "\n",
        "\n",
        "\n",
        "        plt.figure(figsize = (8, 8))\n",
        "        plt.subplot(2, 1, 1)\n",
        "        plt.plot(acc, label = 'Training Accuracy')\n",
        "        plt.plot(val_acc, label = 'Validation Accuracy')\n",
        "\n",
        "        plt.ylim([acc_y_lower_lim, 1])\n",
        "        plt.plot([initial_epochs - 0.15, initial_epochs - 0.15],\n",
        "        plt.ylim(), label = 'Start Fine Tuning')\n",
        "        plt.legend(loc = 'lower right')\n",
        "        plt.title(f'Training and Validation Accuracy for {model_name}')\n",
        "        plt.subplot(2, 1, 2)\n",
        "        plt.plot(loss, label = 'Training Loss')\n",
        "        plt.plot(val_loss, label = 'Validation Loss')\n",
        "\n",
        "\n",
        "        plt.ylim([0, loss_y_upper_limit])\n",
        "        plt.plot([initial_epochs - 0.15,initial_epochs - 0.15],\n",
        "        plt.ylim(), label = 'Start Fine Tuning')\n",
        "        plt.legend(loc = 'upper right')\n",
        "        plt.title(f'Training and Validation Loss for {model_name}')\n",
        "        plt.xlabel('epoch')\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "    # Method to print classification report and plot confusion matrix\n",
        "    def classification_report_and_confusion_metrics(self, test_ds):\n",
        "      y_true = test_ds.labels\n",
        "\n",
        "      class_labels = ['Benign', 'Malignant']\n",
        "\n",
        "      y_pred = self.model.predict(test_ds)\n",
        "\n",
        "      y_pred = np.round(y_pred).flatten()\n",
        "\n",
        "      print(classification_report(y_true, y_pred, target_names = class_labels, digits = 4))\n",
        "\n",
        "\n",
        "      cnn_cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "      plt.figure(figsize=(10, 8))\n",
        "\n",
        "      sns.heatmap(cnn_cm, annot = True, fmt = \"d\", cmap = \"Blues\", cbar = True, xticklabels = class_labels,\n",
        "                  yticklabels = class_labels)\n",
        "\n",
        "      plt.title('CNN Model Confusion Matrix')\n",
        "      plt.xlabel('Predicted Labels')\n",
        "      plt.ylabel('True Labels')\n",
        "\n",
        "      plt.show()"
      ],
      "metadata": {
        "id": "vL2VsUsyjlrl"
      },
      "execution_count": null,
      "outputs": [],
      "id": "vL2VsUsyjlrl"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### VGG16"
      ],
      "metadata": {
        "id": "DawiqjUWBUpH"
      },
      "id": "DawiqjUWBUpH"
    },
    {
      "cell_type": "code",
      "source": [
        "# Creates an instance of the class Finetune_pretrained_models for VGG16 model\n",
        "\n",
        "VGG16 = Finetune_pretrained_models(tf.keras.applications.VGG16)"
      ],
      "metadata": {
        "id": "Ttms0ScqBNCq"
      },
      "id": "Ttms0ScqBNCq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze all the layers of the VGG16 model\n",
        "\n",
        "VGG16.freeze_pretrained_model_layers()"
      ],
      "metadata": {
        "id": "mvcN00d3BNJn"
      },
      "id": "mvcN00d3BNJn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the architecture and print the summary for the VGG16 model\n",
        "\n",
        "VGG16.define_pretrained_model_architecture(0.2, 1e-4)"
      ],
      "metadata": {
        "id": "3MVbldMlBNQ5"
      },
      "id": "3MVbldMlBNQ5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the VGG16 model on the skin cancer dataset\n",
        "\n",
        "VGG16.fit_model(10)"
      ],
      "metadata": {
        "id": "r9relxlSBNV_"
      },
      "id": "r9relxlSBNV_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finetune the VGG16 model\n",
        "\n",
        "VGG16.unfreeze_pretrained_model_layers(1e-7)"
      ],
      "metadata": {
        "id": "R8JYsuAMBNaH"
      },
      "id": "R8JYsuAMBNaH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the finetuned VGG16 model on the skin cancer dataset\n",
        "\n",
        "VGG16.fit_fine_tuned_model(10)"
      ],
      "metadata": {
        "id": "CZJVpISkBhr4"
      },
      "id": "CZJVpISkBhr4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training and validation accuracy and loss\n",
        "\n",
        "VGG16.plot_accuracy_and_loss('VGG16', 0.50, 1.0)"
      ],
      "metadata": {
        "id": "Nj3TAw_xBh8n"
      },
      "id": "Nj3TAw_xBh8n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the classification report and plot the confusion matrix\n",
        "\n",
        "VGG16.classification_report_and_confusion_metrics(test_ds)"
      ],
      "metadata": {
        "id": "DN5bHLpaBnuA"
      },
      "id": "DN5bHLpaBnuA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### InceptionV3"
      ],
      "metadata": {
        "id": "ibQoaa6HCqcR"
      },
      "id": "ibQoaa6HCqcR"
    },
    {
      "cell_type": "code",
      "source": [
        "# Creates an instance of the class Finetune_pretrained_models for InceptionV3 model\n",
        "\n",
        "InceptionV3 = Finetune_pretrained_models(tf.keras.applications.InceptionV3)"
      ],
      "metadata": {
        "id": "-Vl4KqJWCtqw"
      },
      "id": "-Vl4KqJWCtqw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze all the layers of the InceptionV3 model\n",
        "\n",
        "InceptionV3.freeze_pretrained_model_layers()"
      ],
      "metadata": {
        "id": "wUPo6rlPCx1h"
      },
      "id": "wUPo6rlPCx1h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the architecture and print the summary for the InceptionV3 model\n",
        "\n",
        "InceptionV3.define_pretrained_model_architecture(0.2, 1e-4)"
      ],
      "metadata": {
        "id": "PBHn8dyWCx9x"
      },
      "id": "PBHn8dyWCx9x",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the InceptionV3 model on the skin cancer dataset\n",
        "\n",
        "InceptionV3.fit_model(10)"
      ],
      "metadata": {
        "id": "OVtThn1qCyFA"
      },
      "id": "OVtThn1qCyFA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finetune the InceptionV3 model\n",
        "\n",
        "InceptionV3.unfreeze_pretrained_model_layers(1e-7)"
      ],
      "metadata": {
        "id": "XKJuuJsnCyMJ"
      },
      "id": "XKJuuJsnCyMJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the finetuned InceptionV3 model on the skin cancer dataset\n",
        "\n",
        "InceptionV3.fit_fine_tuned_model(10)"
      ],
      "metadata": {
        "id": "N7G7aq4zCyS4"
      },
      "id": "N7G7aq4zCyS4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training and validation accuracy and loss\n",
        "\n",
        "InceptionV3.plot_accuracy_and_loss('InceptionV3', 0.50, 1.0)"
      ],
      "metadata": {
        "id": "y4bbClCDCyZl"
      },
      "id": "y4bbClCDCyZl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the classification report and plot the confusion matrix\n",
        "\n",
        "InceptionV3.classification_report_and_confusion_metrics(test_ds)"
      ],
      "metadata": {
        "id": "dZCzbvRtCyfo"
      },
      "id": "dZCzbvRtCyfo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ResNet101"
      ],
      "metadata": {
        "id": "cWEwz95CDVhd"
      },
      "id": "cWEwz95CDVhd"
    },
    {
      "cell_type": "code",
      "source": [
        "# Creates an instance of the class Finetune_pretrained_models for ResNet101 model\n",
        "\n",
        "ResNet101 = Finetune_pretrained_models(tf.keras.applications.ResNet101)"
      ],
      "metadata": {
        "id": "2fuFnt1wDcL3"
      },
      "id": "2fuFnt1wDcL3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze all the layers of the ResNet101 model\n",
        "\n",
        "ResNet101.freeze_pretrained_model_layers()"
      ],
      "metadata": {
        "id": "gMHDhig1DctY"
      },
      "id": "gMHDhig1DctY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the architecture and print the summary for the ResNet101 model\n",
        "\n",
        "ResNet101.define_pretrained_model_architecture(0.2, 1e-4)"
      ],
      "metadata": {
        "id": "v_XDbAPlDc0Y"
      },
      "id": "v_XDbAPlDc0Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the ResNet101 model on the skin cancer dataset\n",
        "\n",
        "ResNet101.fit_model(10)"
      ],
      "metadata": {
        "id": "1FRnXf41Dc7y"
      },
      "id": "1FRnXf41Dc7y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finetune the ResNet101 model\n",
        "\n",
        "ResNet101.unfreeze_pretrained_model_layers(1e-7)"
      ],
      "metadata": {
        "id": "UXpZnE0UDdFA"
      },
      "id": "UXpZnE0UDdFA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the finetuned ResNet101 model on the skin cancer dataset\n",
        "\n",
        "ResNet101.fit_fine_tuned_model(10)"
      ],
      "metadata": {
        "id": "f_p19cyqDdOQ"
      },
      "id": "f_p19cyqDdOQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training and validation accuracy and loss\n",
        "\n",
        "ResNet101.plot_accuracy_and_loss('ResNet101', 0.50, 1.0)"
      ],
      "metadata": {
        "id": "VapRB1uSDdUp"
      },
      "id": "VapRB1uSDdUp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the classification report and plot the confusion matrix\n",
        "\n",
        "ResNet101.classification_report_and_confusion_metrics(test_ds)"
      ],
      "metadata": {
        "id": "JaztSusdDdaF"
      },
      "id": "JaztSusdDdaF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### MobileNetV2"
      ],
      "metadata": {
        "id": "mVJrIcdpHjEb"
      },
      "id": "mVJrIcdpHjEb"
    },
    {
      "cell_type": "code",
      "source": [
        "# Creates an instance of the class Finetune_pretrained_models for MobileNetV2 model\n",
        "\n",
        "MobileNetV2 = Finetune_pretrained_models(tf.keras.applications.MobileNetV2)"
      ],
      "metadata": {
        "id": "qbHkcr6sHmKC"
      },
      "id": "qbHkcr6sHmKC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze all the layers of the MobileNetV2 model\n",
        "\n",
        "MobileNetV2.freeze_pretrained_model_layers()"
      ],
      "metadata": {
        "id": "OO-6zLBTHmm6"
      },
      "id": "OO-6zLBTHmm6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the architecture and print the summary for the MobileNetV2 model\n",
        "\n",
        "MobileNetV2.define_pretrained_model_architecture(0.2, 1e-4)"
      ],
      "metadata": {
        "id": "ufP88IsnHmsa"
      },
      "id": "ufP88IsnHmsa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the MobileNetV2 model on the skin cancer dataset\n",
        "\n",
        "MobileNetV2.fit_model(10)"
      ],
      "metadata": {
        "id": "P1JKFRkzHmxH"
      },
      "id": "P1JKFRkzHmxH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finetune the MobileNetV2 model\n",
        "\n",
        "MobileNetV2.unfreeze_pretrained_model_layers(1e-7)"
      ],
      "metadata": {
        "id": "L0yL_F_4Hm1k"
      },
      "id": "L0yL_F_4Hm1k",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the finetuned MobileNetV2 model on the skin cancer dataset\n",
        "\n",
        "MobileNetV2.fit_fine_tuned_model(10)"
      ],
      "metadata": {
        "id": "eBN47jreHm5m"
      },
      "id": "eBN47jreHm5m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training and validation accuracy and loss\n",
        "\n",
        "MobileNetV2.plot_accuracy_and_loss('MobileNetV2', 0.50, 1.0)"
      ],
      "metadata": {
        "id": "HZJN3QNjHm9a"
      },
      "id": "HZJN3QNjHm9a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the classification report and plot the confusion matrix\n",
        "\n",
        "MobileNetV2.classification_report_and_confusion_metrics(test_ds)"
      ],
      "metadata": {
        "id": "Br_csd3tHnBE"
      },
      "id": "Br_csd3tHnBE",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}