{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNiknApfLBvuZKBuji6Q0Aa"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXptpBMiLoK4"
      },
      "source": [
        "<h1>An extended machine learning technique for polycystic ovary syndrome detection using ovary ultrasound image</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeX8wtuoLbmo"
      },
      "source": [
        "<h2>Import Neccessary Libraries</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7WvCxcG8ChM"
      },
      "outputs": [],
      "source": [
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S81vefKZM1ro"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2gQpTFCM7zT"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dRBFuwiN2kk"
      },
      "outputs": [],
      "source": [
        "! cp /content/drive/MyDrive/kaggle_API_credentials/kaggle.json ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsx7Oa0DOBRd"
      },
      "outputs": [],
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RYcUOXGTUBp"
      },
      "outputs": [],
      "source": [
        "! kaggle datasets download -d anaghachoudhari/pcos-detection-using-ultrasound-images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EzIn3P_OAvq"
      },
      "outputs": [],
      "source": [
        "! unzip /content/pcos-detection-using-ultrasound-images.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download -d reedah/polycystic-ovary-ultrasound-images-dataset"
      ],
      "metadata": {
        "id": "o9LgjeZnA2MD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip /content/polycystic-ovary-ultrasound-images-dataset.zip"
      ],
      "metadata": {
        "id": "Swr9PeMUA3Yc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ufJda8dKdaa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuGCfL5YMFwK"
      },
      "source": [
        "<h2>Data Preprocessing</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-ZwPXSpQ_qM"
      },
      "source": [
        "<h4>Define the data directory path</h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sY6QI3n6MMAk"
      },
      "outputs": [],
      "source": [
        "# Define the directory containing the training dataset\n",
        "\n",
        "data_dir = '/content/data/train'\n",
        "\n",
        "# Define the directory containing the testing dataset\n",
        "\n",
        "test_dir = '/content/data/test'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acCkx5TuRSZw"
      },
      "source": [
        "<h4>Define the batch size and image size</h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjPovFgTMQh3"
      },
      "outputs": [],
      "source": [
        "# Define the batch size for training\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Define the dimensions for the images\n",
        "\n",
        "img_height = 224\n",
        "\n",
        "img_width = 224"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>Load and preprocess the train dataset</h4>"
      ],
      "metadata": {
        "id": "fAOuAt5io3X0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TWbbNR4LLnX"
      },
      "outputs": [],
      "source": [
        "train_generator = ImageDataGenerator(\n",
        "\n",
        "    rescale=1.0/255.0,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=0.2,\n",
        "    zoom_range=0.2\n",
        "    )\n",
        "\n",
        "train_ds = train_generator.flow_from_directory(\n",
        "   data_dir,\n",
        "    target_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    class_mode=\"binary\",\n",
        "    shuffle = False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the class weights\n",
        "\n",
        "labels = train_ds.classes\n",
        "\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight=\"balanced\",\n",
        "    classes=np.unique(labels),\n",
        "    y=labels\n",
        ")\n",
        "\n",
        "class_weights = dict(zip(np.unique(labels), class_weights))\n",
        "\n",
        "class_weights"
      ],
      "metadata": {
        "id": "zGo-mI2h7YS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary with the class names as keys and corresponding weights\n",
        "\n",
        "class_weights_dictionary = {cls: weight for cls, weight in class_weights.items()}"
      ],
      "metadata": {
        "id": "R7xPzTLSUeMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiQCM0QVyoFQ"
      },
      "source": [
        "<h4>Remove corrupted images from the test directory</h4>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to remove corrupted images from test_dir\n",
        "\n",
        "def remove_corrupted_images(directory):\n",
        "\n",
        "    for filename in os.listdir(directory):\n",
        "        file_path = os.path.join(directory, filename)\n",
        "\n",
        "        try:\n",
        "\n",
        "            # Try to open the image\n",
        "            img = Image.open(file_path)\n",
        "            img.verify()  # Additional verification\n",
        "\n",
        "        except (UnidentifiedImageError, OSError) as e:\n",
        "\n",
        "            # If UnidentifiedImageError or OSError occurs, the file is likely corrupted\n",
        "\n",
        "            print(f'Removing corrupted file: {file_path}')\n",
        "            os.remove(file_path)"
      ],
      "metadata": {
        "id": "We5JBSvS64nB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the corrupted images from test_dir\n",
        "\n",
        "remove_corrupted_images('/content/data/test/infected')\n",
        "remove_corrupted_images('/content/data/test/notinfected')"
      ],
      "metadata": {
        "id": "uv7iEmc6eaXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>Reading in the test dataset using ImageDataGenerator"
      ],
      "metadata": {
        "id": "bBpR4bbK0EfN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0iFGEmoxrc-"
      },
      "outputs": [],
      "source": [
        "test_generator = ImageDataGenerator(rescale = 1.0 /255.0)\n",
        "\n",
        "test_ds = test_generator.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle = False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qDOjIwJGJ0A"
      },
      "source": [
        "<h2>Hybrid Model</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>Spilt the dataset into training and testing sets</h4>"
      ],
      "metadata": {
        "id": "rb8Qj3erpken"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train, x_test, y_test = train_ds, train_ds.labels, test_ds, test_ds.labels"
      ],
      "metadata": {
        "id": "nN-neUI9ploS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>Load the feature_extractor</h4>"
      ],
      "metadata": {
        "id": "s3Eyif25tiVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VGG16_base_model = tf.keras.applications.VGG16(weights = 'imagenet', include_top = False, input_shape=(img_height, img_width, 3))"
      ],
      "metadata": {
        "id": "F0ujRX7Cp3xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze the layers of the ResNet50_base_model\n",
        "\n",
        "VGG16_base_model.trainable = False\n",
        "\n",
        "# Define the architecture of the feature_extractor's\n",
        "\n",
        "inputs = tf.keras.Input(shape = (224, 224, 3))\n",
        "\n",
        "x = inputs\n",
        "x = VGG16_base_model(x, training = False)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "outputs = tf.keras.layers.Dense(1, activation = 'sigmoid')(x)\n",
        "\n",
        "feature_extractor = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Remove the last layer\n",
        "\n",
        "feature_extractor = tf.keras.Model(inputs = feature_extractor.input, outputs = feature_extractor.layers[-2].output)\n",
        "\n",
        "# Print the feature_extractor's summary\n",
        "\n",
        "feature_extractor.summary()"
      ],
      "metadata": {
        "id": "t1tkemqjvUG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the features from the train set\n",
        "\n",
        "train_features = feature_extractor.predict(x_train)"
      ],
      "metadata": {
        "id": "nBHDR5zvqLUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_for_stacking = train_features"
      ],
      "metadata": {
        "id": "X286DxcNwEX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the features from the test set\n",
        "\n",
        "test_features = feature_extractor.predict(x_test)"
      ],
      "metadata": {
        "id": "fsqQmzu5xUoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h97Ea4sjSkDg"
      },
      "outputs": [],
      "source": [
        "def get_stacking():\n",
        "\n",
        "        level0 = []\n",
        "        level0.append(('Logistic_Regression', LogisticRegression(class_weight = class_weights_dictionary, max_iter = 1000)))\n",
        "        level0.append(('SVM', SVC(class_weight = class_weights_dictionary)))\n",
        "        level0.append(('Decision_Tree', DecisionTreeClassifier(class_weight = class_weights_dictionary)))\n",
        "        level0.append(('KNN', KNeighborsClassifier(weights = 'distance')))\n",
        "        level0.append(('Naive_Bayes', GaussianNB()))\n",
        "\n",
        "        level1 = XGBClassifier(scale_pos_weight = class_weights_dictionary[1])\n",
        "\n",
        "        model = StackingClassifier(estimators = level0, final_estimator = level1, cv = 5)\n",
        "\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stacker = get_stacking()"
      ],
      "metadata": {
        "id": "YX7v2Lj3JqPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stacker.fit(x_for_stacking, y_train)"
      ],
      "metadata": {
        "id": "76WpvAmlJ-Q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = stacker.predict(test_features)"
      ],
      "metadata": {
        "id": "AI2yl4aXK-nS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_labels = ['infected', 'notinfected']"
      ],
      "metadata": {
        "id": "b8h-5cnCLYL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred, target_names = class_labels,  digits = 4))"
      ],
      "metadata": {
        "id": "D-0fdSCbdToq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y_pred = stacker.predict(train_features)"
      ],
      "metadata": {
        "id": "U1HxZ8CQ0OWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_train, train_y_pred, target_names = class_labels,  digits = 4))"
      ],
      "metadata": {
        "id": "NUbZ67SFvhLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "sns.heatmap(cnn_cm, annot = True, fmt = \"d\", cmap = \"Blues\", cbar = True, xticklabels = class_labels,\n",
        "            yticklabels = class_labels)\n",
        "\n",
        "plt.title('Hybrid Model Confusion Matrix')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "i4LP_RJAF8Cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Blurred Dataset A"
      ],
      "metadata": {
        "id": "W2MLw3dcZT3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def blur_images(image):\n",
        "\n",
        "    # Apply Gaussian blur to the image\n",
        "\n",
        "    blurred_image = cv2.GaussianBlur(image, (5, 5), 0)\n",
        "\n",
        "    return blurred_image\n",
        "\n",
        "train_generator = ImageDataGenerator(\n",
        "\n",
        "    rescale=1.0/255.0,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    preprocessing_function = blur_images\n",
        "\n",
        "    )\n",
        "\n",
        "train_ds = train_generator.flow_from_directory(\n",
        "   data_dir,\n",
        "    target_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    class_mode=\"binary\",\n",
        "    shuffle = False\n",
        ")"
      ],
      "metadata": {
        "id": "xIgdCRnZZWNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train, x_test, y_test = train_ds, train_ds.labels, test_ds, test_ds.labels"
      ],
      "metadata": {
        "id": "ydmFYlo8ZwVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the features from the train set\n",
        "\n",
        "train_features = feature_extractor.predict(x_train)"
      ],
      "metadata": {
        "id": "IX0OQirUZxHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_for_stacking = train_features"
      ],
      "metadata": {
        "id": "5hAFOOq9ZxNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the features from the test set\n",
        "\n",
        "test_features = feature_extractor.predict(x_test)"
      ],
      "metadata": {
        "id": "HkRiefv2ZxRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stacker = get_stacking()"
      ],
      "metadata": {
        "id": "GdTQ4bP3ZxUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stacker.fit(x_for_stacking, y_train)"
      ],
      "metadata": {
        "id": "7LNvO5w1ZxXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = stacker.predict(test_features)"
      ],
      "metadata": {
        "id": "uPuFPnHnZxdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred, target_names = class_labels, digits = 4))"
      ],
      "metadata": {
        "id": "X9X3xZtzaN9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y_pred = stacker.predict(train_features)"
      ],
      "metadata": {
        "id": "U52ueWXwaOGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_train, train_y_pred, target_names = class_labels,  digits = 4))"
      ],
      "metadata": {
        "id": "YzEX7GZbaOR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "sns.heatmap(cnn_cm, annot = True, fmt = \"d\", cmap = \"Blues\", cbar = True, xticklabels = class_labels,\n",
        "            yticklabels = class_labels)\n",
        "\n",
        "plt.title('Hybrid Model Confusion Matrix')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tf_XV9A4aYdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATASET B"
      ],
      "metadata": {
        "id": "V3T_6yww3NlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the directory containing the training dataset\n",
        "\n",
        "data_dir = '/content/PCOS dataset/train'\n",
        "\n",
        "# Define the directory containing the testing dataset\n",
        "\n",
        "test_dir = '/content/PCOS dataset/test'"
      ],
      "metadata": {
        "id": "CJLHiaN4FldH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the batch size for training\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "# Define the dimensions for the images\n",
        "\n",
        "img_height = 224\n",
        "\n",
        "img_width = 224"
      ],
      "metadata": {
        "id": "nki27P6D5Puy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def blur_images(image):\n",
        "\n",
        "    # Apply Gaussian blur to the image\n",
        "\n",
        "    blurred_image = cv2.GaussianBlur(image, (5, 5), 0)\n",
        "\n",
        "    return blurred_image\n",
        "\n",
        "train_generator = ImageDataGenerator(\n",
        "\n",
        "    rescale=1.0/255.0,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    preprocessing_function = blur_images\n",
        "\n",
        "    )\n",
        "\n",
        "train_ds = train_generator.flow_from_directory(\n",
        "   data_dir,\n",
        "    target_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'binary',\n",
        "    shuffle = False\n",
        ")"
      ],
      "metadata": {
        "id": "j3T46bQQZ4j_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the class weights\n",
        "\n",
        "labels = train_ds.classes\n",
        "\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight=\"balanced\",\n",
        "    classes=np.unique(labels),\n",
        "    y=labels\n",
        ")\n",
        "\n",
        "class_weights = dict(zip(np.unique(labels), class_weights))\n",
        "\n",
        "class_weights"
      ],
      "metadata": {
        "id": "RVVXlJgS49t1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary with the class names as keys and corresponding weights\n",
        "\n",
        "class_weights_dictionary = {cls: weight for cls, weight in class_weights.items()}"
      ],
      "metadata": {
        "id": "mYzYU0dl5I0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to remove corrupted images from test_dir\n",
        "\n",
        "def remove_corrupted_images(directory):\n",
        "\n",
        "    for filename in os.listdir(directory):\n",
        "        file_path = os.path.join(directory, filename)\n",
        "        try:\n",
        "\n",
        "            # Try to open the image\n",
        "            img = Image.open(file_path)\n",
        "            img.verify()  # Additional verification\n",
        "\n",
        "        except (UnidentifiedImageError, OSError) as e:\n",
        "\n",
        "            # If UnidentifiedImageError or OSError occurs, the file is likely corrupted\n",
        "\n",
        "            print(f'Removing corrupted file: {file_path}')\n",
        "            os.remove(file_path)"
      ],
      "metadata": {
        "id": "KvpE-lIHKTb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the corrupted images from test_dir\n",
        "\n",
        "remove_corrupted_images('/content/PCOS dataset/test/infected')\n",
        "remove_corrupted_images('/content/PCOS dataset/test/notinfected')"
      ],
      "metadata": {
        "id": "TV8Z3L3pKUd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bx_oS_eMv1ZA"
      },
      "outputs": [],
      "source": [
        "test_generator = ImageDataGenerator(rescale = 1.0 /255.0)\n",
        "\n",
        "test_ds = test_generator.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle = False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train, x_test, y_test = train_ds, train_ds.labels, test_ds, test_ds.labels"
      ],
      "metadata": {
        "id": "iTENL__33TKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the features from the train set\n",
        "\n",
        "train_features = feature_extractor.predict(x_train)"
      ],
      "metadata": {
        "id": "crTa1IHx3o3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_for_stacking = train_features"
      ],
      "metadata": {
        "id": "lTSS8cf73ptI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the features from the test set\n",
        "\n",
        "test_features = feature_extractor.predict(x_test)"
      ],
      "metadata": {
        "id": "HMziSI9e3p20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stacker = get_stacking()"
      ],
      "metadata": {
        "id": "wII7QUDB34Yt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stacker.fit(x_for_stacking, y_train)"
      ],
      "metadata": {
        "id": "KLd5iTLq34ez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = stacker.predict(test_features)"
      ],
      "metadata": {
        "id": "ATXg0xHm34qP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_labels = ['infected', 'notinfected']"
      ],
      "metadata": {
        "id": "FruUQfcf5y4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred, target_names = class_labels, digits = 4))"
      ],
      "metadata": {
        "id": "NCSf3ZKL4Klr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y_pred = stacker.predict(train_features)"
      ],
      "metadata": {
        "id": "KVqz8WGaE7aa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_train, train_y_pred, target_names = class_labels,  digits = 4))"
      ],
      "metadata": {
        "id": "I1cGVjJoFPnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "sns.heatmap(cnn_cm, annot = True, fmt = \"d\", cmap = \"Blues\", cbar = True, xticklabels = class_labels,\n",
        "            yticklabels = class_labels)\n",
        "\n",
        "plt.title('Hybrid Model Confusion Matrix')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "evSRcD1w4KtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset C"
      ],
      "metadata": {
        "id": "h-8UnPbpFZFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the directory containing the training dataset\n",
        "\n",
        "data_dir = '/content/data/train'\n",
        "\n",
        "# Define the directory containing the testing dataset\n",
        "\n",
        "test_dir = '/content/data/test'"
      ],
      "metadata": {
        "id": "PrajFGCyFX-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def blur_images(image):\n",
        "\n",
        "    # Apply Gaussian blur to the image\n",
        "\n",
        "    blurred_image = cv2.GaussianBlur(image, (5, 5), 0)\n",
        "\n",
        "    return blurred_image\n",
        "\n",
        "train_generator = ImageDataGenerator(\n",
        "\n",
        "    rescale=1.0/255.0,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    preprocessing_function = blur_images\n",
        "\n",
        "    )\n",
        "\n",
        "train_ds = train_generator.flow_from_directory(\n",
        "   data_dir,\n",
        "    target_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'binary',\n",
        "    shuffle = False\n",
        ")"
      ],
      "metadata": {
        "id": "md-htnsxF2La"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the class weights\n",
        "\n",
        "labels = train_ds.classes\n",
        "\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight=\"balanced\",\n",
        "    classes=np.unique(labels),\n",
        "    y=labels\n",
        ")\n",
        "\n",
        "class_weights = dict(zip(np.unique(labels), class_weights))\n",
        "\n",
        "class_weights"
      ],
      "metadata": {
        "id": "htLG5BIRF2lj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary with the class names as keys and corresponding weights\n",
        "\n",
        "class_weights_dictionary = {cls: weight for cls, weight in class_weights.items()}"
      ],
      "metadata": {
        "id": "7zWGnYTFGCPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator = ImageDataGenerator(rescale = 1.0 /255.0)\n",
        "\n",
        "test_ds = test_generator.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle = False\n",
        ")"
      ],
      "metadata": {
        "id": "SR4KXsY5F2so"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train, x_test, y_test = train_ds, train_ds.labels, test_ds, test_ds.labels"
      ],
      "metadata": {
        "id": "DzG67S71F202"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the features from the train set\n",
        "\n",
        "train_features = feature_extractor.predict(x_train)"
      ],
      "metadata": {
        "id": "VRRixxzTGPsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_for_stacking = train_features"
      ],
      "metadata": {
        "id": "jgZKd40mGP0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the features from the test set\n",
        "\n",
        "test_features = feature_extractor.predict(x_test)"
      ],
      "metadata": {
        "id": "QSp9nrN6GP5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stacker = get_stacking()"
      ],
      "metadata": {
        "id": "RNpQSqvqGjTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stacker.fit(x_for_stacking, y_train)"
      ],
      "metadata": {
        "id": "BwU2DMd_GjYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = stacker.predict(test_features)"
      ],
      "metadata": {
        "id": "8L0f5fPAGjce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred, target_names = class_labels, digits = 4))"
      ],
      "metadata": {
        "id": "4_FIg3QKGQBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y_pred = stacker.predict(train_features)"
      ],
      "metadata": {
        "id": "JvaHWLy8J5Gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_train, train_y_pred, target_names = class_labels,  digits = 4))"
      ],
      "metadata": {
        "id": "QzThg2BLJ5Qt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "sns.heatmap(cnn_cm, annot = True, fmt = \"d\", cmap = \"Blues\", cbar = True, xticklabels = class_labels,\n",
        "            yticklabels = class_labels)\n",
        "\n",
        "plt.title('Hybrid Model Confusion Matrix')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "K9Jqy0BeJ5ep"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}